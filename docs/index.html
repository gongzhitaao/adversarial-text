<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Adversarial Texts with Gradient Methods</title><meta name="generator" content="Org mode"><meta name="author" content="Zhitao Gong"><link rel="stylesheet" href="https://gongzhitaao.org/orgcss/org.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script></head><body><div id="content"><header><h1 class="title">Adversarial Texts with Gradient Methods</h1></header><div class="abstract"><p>This page shows the complete result of our simple adversarial text generation method. You could find the source code and report here <a href="https://github.com/gongzhitaao/adversarial-text">github/gongzhitaao/adversarial-text</a>. Due to some reasons, the paper is withdrawn from arXiV. It is only available on GitHub.</p></div><nav id="table-of-contents"><h2>Table of Contents</h2><div id="text-table-of-contents"><ul><li><a href="#h1-introduction-238f4">1. Introduction</a></li><li><a href="#h1-method-157a9">2. Method</a></li><li><a href="#sec:result">3. Result</a><ul><li><a href="#subsec:fgsm">3.1. Fast Gradient Sign Method (FGSM)</a></li><li><a href="#subsec:fgvm">3.2. Fast Gradient Value Method (FGVM)</a></li><li><a href="#subsec:deepfool">3.3. DeepFool</a></li></ul></li></ul></div></nav><div id="outline-container-org94a3b77" class="outline-2"><h2 id="h1-introduction-238f4"><span class="section-number-2">1</span> Introduction</h2><div class="outline-text-2" id="text-h1-introduction-238f4"><p>It has been shown in [<a href="#szegedy2013-intriguing">6</a>] that we can apply very subtle noise to images to trick deep learning into wrong prediction with very high confident. One example in shown in Figure <a href="#org98e4e42">1</a>. A set of adversarial images via different attacking algorithms are generated from a random image from MNIST dataset. The upper image in <i>Clean</i> column is the original clean image. The upper images in the following columns are adversarial images generated by the corresponding attacking algorithm, based on the first clean image, respectively. The lower image in each column is the differece between the adversarial image and the clean image, illustrated in heatmap. Below each column is the label predicted by the target model, along with probability in parenthesis. The algorithms demonstrated are FGSM [<a href="#goodfellow2014-explaining">1</a>], FGVM [<a href="#miyato2015-distributional">2</a>], JSMA [<a href="#papernot2015-limitations">4</a>] and DeepFool [<a href="#moosavi-dezfooli2015-deepfool">3</a>]. These are all gradient attacking methods.</p><figure id="org98e4e42"><img src="img/imgdemo.png" alt="imgdemo.png" width="70%"><figcaption><span class="figure-number">Figure 1: </span>Adversarial examples created on MNIST</figcaption></figure></div></div><div id="outline-container-org1ed580d" class="outline-2"><h2 id="h1-method-157a9"><span class="section-number-2">2</span> Method</h2><div class="outline-text-2" id="text-h1-method-157a9"><p>Our method is straightforward. We find the adversarial text in the <i>embedding space</i>, e.g. [<a href="#pennington2014-glove">5</a>]. Part of the difficulty of generating adversarial texts is the discreteness of the input space. Instead of working in the raw input space, we first use the above method to find <i>candidate adversarial embeddings</i> in the embedding space, and use <i>nearest neighbor</i> to find the corresponding adversarial tokens. Since the embedding space is continuous, finding adversarials is the same as images. Similar to images, most of the time we only need to modify a couple tokens (out of hundreds) to change to fool different text models.</p><p>The downside of this method is that we do not have control over the quality (e.g., syntax, semantics) of the generated sentences.</p></div></div><div id="outline-container-org77360bf" class="outline-2"><h2 id="sec:result"><span class="section-number-2">3</span> Result</h2><div class="outline-text-2" id="text-sec:result"><p>Due to the size of the dataset, we only show 100 samples for each parameter setting on the website. The rest samples could be downloaded. Note that some tokens in the clean dataset are different from the original piece of text, since these texts are also reconstructed by approximate nearest neighbor search for convenience. These does not affect the embedded vectors.</p></div><div id="outline-container-org349e471" class="outline-3"><h3 id="subsec:fgsm"><span class="section-number-3">3.1</span> Fast Gradient Sign Method (FGSM)</h3><div class="outline-text-3" id="text-subsec:fgsm"><p>This was proposed in [<a href="#goodfellow2014-explaining">1</a>]. The adversarial noise is computed as \(z = \epsilon \text{sign}\nabla L\).</p><table id="orgdddd7fa"><caption class="t-above"><span class="table-number">Table 1:</span> Adversarial text via FGSM</caption><colgroup><col class="org-left"><col class="org-left"><col class="org-left"><col class="org-left"><col class="org-left"></colgroup><thead><tr><th scope="col" class="org-left">&epsilon;</th><th scope="col" class="org-left">0.40</th><th scope="col" class="org-left">0.35</th><th scope="col" class="org-left">0.30</th><th scope="col" class="org-left">0.25</th></tr></thead><tbody><tr><td class="org-left">IMDB</td><td class="org-left"><a href="result/imdb_fgsm_eps0.40.html">0.1213 / 0.1334</a></td><td class="org-left"><a href="result/imdb_fgsm_eps0.35.html">0.1213 / 0.1990</a></td><td class="org-left"><a href="result/imdb_fgsm_eps0.30.html">0.1213 / 0.4074</a></td><td class="org-left"><a href="result/imdb_fgsm_eps0.25.html">0.1213 / 0.6770</a></td></tr><tr><td class="org-left">Reuters-2</td><td class="org-left"><a href="result/reuters2_fgsm_eps0.40.html">0.0146 / 0.6495</a></td><td class="org-left"><a href="result/reuters2_fgsm_eps0.35.html">0.0146 / 0.7928</a></td><td class="org-left"><a href="result/reuters2_fgsm_eps0.30.html">0.0146 / 0.9110</a></td><td class="org-left"><a href="result/reuters2_fgsm_eps0.25.html">0.0146 / 0.9680</a></td></tr><tr><td class="org-left">Reuters-5</td><td class="org-left"><a href="result/reuters5_fgsm_eps0.40.html">0.1128 / 0.5880</a></td><td class="org-left"><a href="result/reuters5_fgsm_eps0.35.html">0.1128 / 0.7162</a></td><td class="org-left"><a href="result/reuters5_fgsm_eps0.30.html">0.1128 / 0.7949</a></td><td class="org-left"><a href="result/reuters5_fgsm_eps0.25.html">0.1128 / 0.8462</a></td></tr></tbody></table></div></div><div id="outline-container-org7ca44ea" class="outline-3"><h3 id="subsec:fgvm"><span class="section-number-3">3.2</span> Fast Gradient Value Method (FGVM)</h3><div class="outline-text-3" id="text-subsec:fgvm"><p>This is a variant of FGSM, instead of gradients, FGVM uses the gradients directly. The noise is \(z = \epsilon\frac{\nabla L}{\|\nabla L\|_2}\).</p><table id="orgd565d66"><caption class="t-above"><span class="table-number">Table 2:</span> Adversarial text via FGVM</caption><colgroup><col class="org-left"><col class="org-left"><col class="org-left"><col class="org-left"><col class="org-left"></colgroup><thead><tr><th scope="col" class="org-left">&epsilon;</th><th scope="col" class="org-left">15</th><th scope="col" class="org-left">30</th><th scope="col" class="org-left">50</th><th scope="col" class="org-left">100</th></tr></thead><tbody><tr><td class="org-left">IMDB</td><td class="org-left"><a href="result/imdb_fgvm_eps15.html">0.6888 / 0.8538</a></td><td class="org-left"><a href="result/imdb_fgvm_eps30.html">0.6549 / 0.8354</a></td><td class="org-left"><a href="result/imdb_fgvm_eps50.html">0.6277 / 0.8207</a></td><td class="org-left"><a href="result/imdb_fgvm_eps100.html">0.5925 / 0.7964</a></td></tr><tr><td class="org-left">Reuters-2</td><td class="org-left"><a href="result/reuters2_fgvm_eps15.html">0.7747 / 0.7990</a></td><td class="org-left"><a href="result/reuters2_fgvm_eps30.html">0.7337 / 0.7538</a></td><td class="org-left"><a href="result/reuters2_fgvm_eps50.html">0.6975 / 0.7156</a></td><td class="org-left"><a href="result/reuters2_fgvm_eps100.html">0.6349 / 0.6523</a></td></tr><tr><td class="org-left">Reuters-5</td><td class="org-left"><a href="result/reuters5_fgvm_eps15.html">0.5915 / 0.7983</a></td><td class="org-left"><a href="result/reuters5_fgvm_eps30.html">0.5368 / 0.6872</a></td><td class="org-left"><a href="result/reuters5_fgvm_eps50.html">0.4786 / 0.6085</a></td><td class="org-left"><a href="result/reuters5_fgvm_eps100.html">0.4000 / 0.5111</a></td></tr></tbody></table></div></div><div id="outline-container-orgb9b87b7" class="outline-3"><h3 id="subsec:deepfool"><span class="section-number-3">3.3</span> DeepFool</h3><div class="outline-text-3" id="text-subsec:deepfool"><p>This method is proposed in [<a href="#moosavi-dezfooli2015-deepfool">3</a>]. DeepFool iteratively finds the optimal direction in which we need to <i>travel</i> the minimum distance to cross the decision boundary of the target model. Although in non-linear cases, this optimality is not guaranteed, DeepFool works well in practice, and usually generates very subtle noise. In many of the examples, DeepFool alters the label of the text piece by replace only one word.</p><table id="orgbe59439"><caption class="t-above"><span class="table-number">Table 3:</span> Adversarial text via DeepFool</caption><colgroup><col class="org-left"><col class="org-left"><col class="org-left"><col class="org-left"><col class="org-left"></colgroup><thead><tr><th scope="col" class="org-left">&epsilon;</th><th scope="col" class="org-left">20</th><th scope="col" class="org-left">30</th><th scope="col" class="org-left">40</th><th scope="col" class="org-left">50</th></tr></thead><tbody><tr><td class="org-left">IMDB</td><td class="org-left"><a href="result/imdb_deepfool_eps20.html">0.5569 / 0.8298</a></td><td class="org-left"><a href="result/imdb_deepfool_eps30.html">0.5508 / 0.7225</a></td><td class="org-left"><a href="result/imdb_deepfool_eps40.html">0.5472 / 0.6678</a></td><td class="org-left"><a href="result/imdb_deepfool_eps50.html">0.5453 / 0.6416</a></td></tr><tr><td class="org-left">Reuters-2</td><td class="org-left"><a href="result/reuters2_deepfool_eps20.html">0.4416 / 0.6766</a></td><td class="org-left"><a href="result/reuters2_deepfool_eps30.html">0.4416 / 0.5236</a></td><td class="org-left"><a href="result/reuters2_deepfool_eps40.html">0.4416 / 0.4910</a></td><td class="org-left"><a href="result/reuters2_deepfool_eps50.html">0.4416 / 0.4715</a></td></tr><tr><td class="org-left">Reuters-5</td><td class="org-left"><a href="result/reuters5_deepfool_eps20.html">0.1163 / 0.4034</a></td><td class="org-left"><a href="result/reuters5_deepfool_eps30.html">0.1162 / 0.2222</a></td><td class="org-left"><a href="result/reuters5_deepfool_eps40.html">0.1162 / 0.1641</a></td><td class="org-left"><a href="result/reuters5_deepfool_eps50.html">0.1162 / 0.1402</a></td></tr></tbody></table></div></div></div><div id="bibliography"><h2>References</h2><table><tr valign="top"><td align="right" class="bibtexnumber">[<a name="goodfellow2014-explaining">1</a>]</td><td class="bibtexitem">I.&nbsp;J. Goodfellow, J.&nbsp;Shlens, and C.&nbsp;Szegedy. Explaining and Harnessing Adversarial Examples. <em>ArXiv e-prints</em>, December 2014. [&nbsp;<a href="refdb_bib.html#goodfellow2014-explaining">bib</a>&nbsp;| <a href="http://arxiv.org/abs/1412.6572">arXiv</a>&nbsp;]</td></tr><tr valign="top"><td align="right" class="bibtexnumber">[<a name="miyato2015-distributional">2</a>]</td><td class="bibtexitem">Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, Ken Nakae, and Shin Ishii. Distributional smoothing with virtual adversarial training. <em>stat</em>, 1050:25, 2015. [&nbsp;<a href="refdb_bib.html#miyato2015-distributional">bib</a>&nbsp;]</td></tr><tr valign="top"><td align="right" class="bibtexnumber">[<a name="moosavi-dezfooli2015-deepfool">3</a>]</td><td class="bibtexitem">Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard. Deepfool: a simple and accurate method to fool deep neural networks. <em>CoRR</em>, abs/1511.04599, 2015. [&nbsp;<a href="refdb_bib.html#moosavi-dezfooli2015-deepfool">bib</a>&nbsp;| <a href="http://arxiv.org/abs/1511.04599">arXiv</a>&nbsp;| <a href="http://arxiv.org/abs/1511.04599">http</a>&nbsp;]</td></tr><tr valign="top"><td align="right" class="bibtexnumber">[<a name="papernot2015-limitations">4</a>]</td><td class="bibtexitem">Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z.&nbsp;Berkay Celik, and Ananthram Swami. The limitations of deep learning in adversarial settings. <em>CoRR</em>, abs/1511.07528, 2015. [&nbsp;<a href="refdb_bib.html#papernot2015-limitations">bib</a>&nbsp;| <a href="http://arxiv.org/abs/1511.07528">http</a>&nbsp;]</td></tr><tr valign="top"><td align="right" class="bibtexnumber">[<a name="pennington2014-glove">5</a>]</td><td class="bibtexitem">Jeffrey Pennington, Richard Socher, and Christopher Manning. Glove: Global vectors for word representation. In <em>Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</em>, pages 1532--1543, 2014. [&nbsp;<a href="refdb_bib.html#pennington2014-glove">bib</a>&nbsp;]</td></tr><tr valign="top"><td align="right" class="bibtexnumber">[<a name="szegedy2013-intriguing">6</a>]</td><td class="bibtexitem">Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian&nbsp;J. Goodfellow, and Rob Fergus. Intriguing properties of neural networks. <em>CoRR</em>, abs/1312.6199, 2013. [&nbsp;<a href="refdb_bib.html#szegedy2013-intriguing">bib</a>&nbsp;| <a href="http://arxiv.org/abs/1312.6199">http</a>&nbsp;]</td></tr></table></div></div><div id="postamble" class="status"><a class="author" href="http://gongzhitaao.org">Zhitao Gong</a> / <span class="date">2018-12-09 Sun 12:35</span><span class="creator"><a href="https://www.gnu.org/software/emacs/">Emacs</a> 25.2.2 (<a href="https://orgmode.org">Org</a> mode 9.1.14)</span></div></body></html>