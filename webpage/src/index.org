#+TITLE: Adversarial Texts with Gradient Methods
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="http://gongzhitaao.org/orgcss/org.css"/>

* Abstract                                                           :ignore:

#+BEGIN_abstract
#+END_abstract

* Introduction

It has been shown in cite:szegedy2013-intriguing that we can apply very subtle
noise to images to trick deep learning into wrong prediction with very high
confident.  One example in shown in Figure [[fig:imgdemo]].  A set of adversarial
images via different attacking algorithms are generated from a random image from
MNIST dataset.  The upper image in /Clean/ column is the original clean image.
The upper images in the following columns are adversarial images generated by
the corresponding attacking algorithm, based on the first clean image,
respectively.  The lower image in each column is the differece between the
adversarial image and the clean image, illustrated in heatmap.  Below each
column is the label predicted by the target model, along with probability in
parenthesis.  The algorithms demonstrated are
FGSM cite:goodfellow2014-explaining, FGVM cite:miyato2015-distributional,
JSMA cite:papernot2015-limitations and
DeepFool cite:moosavi-dezfooli2015-deepfool.  These are all gradient attacking
methods.

#+CAPTION: Adversarial examples created on MNIST
#+NAME: fig:imgdemo
[[file:img/imgdemo.png]]

* Result
:PROPERTIES:
:CUSTOM_ID: sec:result
:END:

Due to the size of the dataset, we only show 100 samples for each parameter
setting on the website.  The rest samples could be downloaded.  Note that some
tokens in the clean dataset are different from the original piece of text, since
these texts are also reconstructed by approximate nearest neighbor search for
convenience.  These does not affect the embedded vectors.

** Fast Gradient Sign Method (FGSM)
:PROPERTIES:
:CUSTOM_ID: subsec:fgsm
:END:

This was proposed in cite:goodfellow2014-explaining.  The adversarial noise is
computed as \(z = \epsilon \text{sign}\nabla L\).

#+CAPTION: Adversarial text via FGSM
#+NAME: tab:textadv-fgsm
| \epsilon  | 0.40            | 0.35            | 0.30            | 0.25            |
|-----------+-----------------+-----------------+-----------------+-----------------|
| IMDB      | [[file:result/imdb_fgsm_eps0.40.html][0.1213 / 0.1334]] | [[file:result/imdb_fgsm_eps0.35.html][0.1213 / 0.1990]] | [[file:result/imdb_fgsm_eps0.30.html][0.1213 / 0.4074]] | [[file:result/imdb_fgsm_eps0.25.html][0.1213 / 0.6770]] |
| Reuters-2 | [[file:result/reuters2_fgsm_eps0.40.html][0.0146 / 0.6495]] | [[file:result/reuters2_fgsm_eps0.35.html][0.0146 / 0.7928]] | [[file:result/reuters2_fgsm_eps0.30.html][0.0146 / 0.9110]] | [[file:result/reuters2_fgsm_eps0.25.html][0.0146 / 0.9680]] |
| Reuters-5 | [[file:result/reuters5_fgsm_eps0.40.html][0.1128 / 0.5880]] | [[file:result/reuters5_fgsm_eps0.35.html][0.1128 / 0.7162]] | [[file:result/reuters5_fgsm_eps0.30.html][0.1128 / 0.7949]] | [[file:result/reuters5_fgsm_eps0.25.html][0.1128 / 0.8462]] |

** Fast Gradient Value Method (FGVM)
:PROPERTIES:
:CUSTOM_ID: subsec:fgvm
:END:

This is a variant of FGSM, instead of gradients, FGVM uses the gradients
directly.  The noise is \(z = \epsilon\frac{\nabla L}{\|\nabla L\|_2}\).

#+CAPTION: Adversarial text via FGVM
#+NAME: tab:textadv-fgvm
| \epsilon  | 15              | 30              | 50              | 100             |
|-----------+-----------------+-----------------+-----------------+-----------------|
| IMDB      | [[file:result/imdb_fgvm_eps15.html][0.6888 / 0.8538]] | [[file:result/imdb_fgvm_eps30.html][0.6549 / 0.8354]] | [[file:result/imdb_fgvm_eps50.html][0.6277 / 0.8207]] | [[file:result/imdb_fgvm_eps100.html][0.5925 / 0.7964]] |
| Reuters-2 | [[file:result/reuters2_fgvm_eps15.html][0.7747 / 0.7990]] | [[file:result/reuters2_fgvm_eps30.html][0.7337 / 0.7538]] | [[file:result/reuters2_fgvm_eps50.html][0.6975 / 0.7156]] | [[file:result/reuters2_fgvm_eps100.html][0.6349 / 0.6523]] |
| Reuters-5 | [[file:result/reuters5_fgvm_eps15.html][0.5915 / 0.7983]] | [[file:result/reuters5_fgvm_eps30.html][0.5368 / 0.6872]] | [[file:result/reuters5_fgvm_eps50.html][0.4786 / 0.6085]] | [[file:result/reuters5_fgvm_eps100.html][0.4000 / 0.5111]] |

** DeepFool
:PROPERTIES:
:CUSTOM_ID: subsec:deepfool
:END:

This method is proposed in cite:moosavi-dezfooli2015-deepfool.  DeepFool
iteratively finds the optimal direction in which we need to /travel/ the minimum
distance to cross the decision boundary of the target model.  Although in
non-linear cases, this optimality is not guaranteed, DeepFool works well in
practice, and usually generates very subtle noise.  In many of the examples,
DeepFool alters the label of the text piece by replace only one word.

#+CAPTION: Adversarial text via DeepFool
#+NAME: tab:textadv-deepfool
| \epsilon  | 20              | 30              | 40              | 50              |
|-----------+-----------------+-----------------+-----------------+-----------------|
| IMDB      | [[file:result/imdb_deepfool_eps20.html][0.5569 / 0.8298]] | [[file:result/imdb_deepfool_eps30.html][0.5508 / 0.7225]] | [[file:result/imdb_deepfool_eps40.html][0.5472 / 0.6678]] | [[file:result/imdb_deepfool_eps50.html][0.5453 / 0.6416]] |
| Reuters-2 | [[file:result/reuters2_deepfool_eps20.html][0.4416 / 0.6766]] | [[file:result/reuters2_deepfool_eps30.html][0.4416 / 0.5236]] | [[file:result/reuters2_deepfool_eps40.html][0.4416 / 0.4910]] | [[file:result/reuters2_deepfool_eps50.html][0.4416 / 0.4715]] |
| Reuters-5 | [[file:result/reuters5_deepfool_eps20.html][0.1163 / 0.4034]] | [[file:result/reuters5_deepfool_eps30.html][0.1162 / 0.2222]] | [[file:result/reuters5_deepfool_eps40.html][0.1162 / 0.1641]] | [[file:result/reuters5_deepfool_eps50.html][0.1162 / 0.1402]] |

* Reference                                                          :ignore:

#+BIBLIOGRAPHY: nn.bib plain limit:t option:-nokeywords
